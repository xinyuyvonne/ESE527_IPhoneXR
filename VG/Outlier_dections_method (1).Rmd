---
title: "Homework 2: Outlier Detection Review"
author: "Patricio S. La Rosa"
date: "2/23/2020"
output: 
  html_document: 
    keep_md: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Deep-Dive on Outlier detection Methods

The purpose of this homework is to review several outlier detection methods made avialable through R packages. After completition of this homework you should be familiarized with standard methods for univariate and multivariate outlier detection methods. Application of these techniques to you project, as it applies, will be requested and will be considered as part of your mid-term report.  

For more details on how to work with RmarkDown please read the following link:
https://www.stat.cmu.edu/~cshalizi/rmarkdown/

Please install the following packages prior to execute the R Markdown:
install.packages(c("OutlierDetection","OutliersO3","outliers"))

```{r}
library(OutlierDetection)
library(OutliersO3)
library(outliers)
```


## Data Description:

We will proceed now to summarize the classical Toy Example iris:

The Fisher's or Anderson's iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica. For more information about the data set, execute 

```{r iris}
help(iris)
summary(iris)
head(iris)

```


## Problem 1: Expanding knowledge based on Outlier detection techniques
The objective of this problem is to expose the student to different outlier detection techniques made available through R packages. The goal is to ensure that the main assumptions of these techniques are learned and the students is capable of articulating how the technique works statistically and in practice by using a toy example.

As discussed in our lecture, outlier detection techniques can be classified as follows:

1.-Statistical Tests based Approaches
2. Depth-based Approaches
3. Deviation-based Approaches
4. Distance-based Approaches
5. Density-based Approaches

Your task is to complete this Rmarkdown with a technical summary describing each of the technique entitled below and use the toy example to describe its application.


### 1.-Statistical Tests based Approaches:

#### a) Dixon test (small sample size)

Technical Summary:

References:
- Dixon, W.J. (1950). Analysis of extreme values. Ann. Math. Stat. 21, 4, 488-506.
- Dixon, W.J. (1951). Ratios involving extreme values. Ann. Math. Stat. 22, 1, 68-78.
- Rorabacher, D.B. (1991). Statistical Treatment for Rejection of Deviant Values: Critical Values of Dixon Q Parameter and Related Subrange Ratios at the 95 percent Confidence Level. Anal. Chem.
83, 2, 139-146.

Application:

```{r}
X=iris[1:30,1]
dixon.test(X,type=0,opposite=TRUE)

```
#### b) Normalscore (Deviation with respect to the mean)

Technical Summary:


References:
Schiffler, R.E (1998). Maximum Z scores and outliers. Am. Stat. 42, 1, 79-80.

Application:

```{r}
X=iris[,1:4]
#scores(X,type="z",prob=0.95)
#Displaying first 10 scores
scores(X,type="z",prob=0.95)[1:10,]

```


#### c) Median Absolute Deviation (Deviation with respect to the median)

Technical Summary:


References:
Schiffler, R.E (1998). Maximum Z scores and outliers. Am. Stat. 42, 1, 79-80.

```{r}
X=iris[,1:4]
#scores(X,type="mad",prob=0.95)
#Displaying first 10 scores
scores(X,type="mad",prob=0.95)[1:10,]

```


#### d) Interquantile range score

Technical Summary:


References:
Schiffler, R.E (1998). Maximum Z scores and outliers. Am. Stat. 42, 1, 79-80.

Note: check for the value of limit to be used. Below I inserted an arbitrary value
```{r}
X=iris[,1:4]
#scores(X,type="iqr",lim=1)
#Displaying first 10 scores
scores(X,type="iqr",lim=1)[1:10,]
```


### 2. Depth-based Approach:

Technical Summary:


Reference:
Johnson, T., Kwok, I., and Ng, R.T. 1998. Fast computation of 2-dimensional depth contours. In Proc. Int. Conf. on Knowledge Discovery and Data Mining (KDD), New York, NY. Kno

Application:

```{r}
X=iris[,1:4]
depthout(X,cutoff=0.05)



```

### 3. Deviation-based Approaches
Technical Summary:

References:
A. Arning, R. Agrawal, and P. Raghavan. A linear method for deviation detection in large
databases. In Proc. 2nd International Conference on Knowledge Discovery and Data Mining,
1996
Chaudhary, A., Szalay, A. S., and Moore, A. W. 2002. Very fast outlier detection in large multidimensional data sets. In Proceedings of the ACM SIGMOD Workshop in Research Issues in Data Mining and Knowledge Discovery (DMKD). ACM Press


### 4. Distance-based Approaches
#### a) Outlier detection using Mahalanobis Distance
Technical Summary:

References:
Barnett, V. 1978. The study of outliers: purpose and model. Applied Statistics, 27(3), 242â€“250.

Application:
```{r}
X=iris[,1:4]
maha(X,cutoff=0.9)
```

#### b) Outlier detection using k Nearest Neighbours Distance method
Technical Summary:

References:
Hautamaki, V., Karkkainen, I., and Franti, P. 2004. Outlier detection using k-nearest neighbour graph. In Proc. IEEE Int. Conf. on Pattern Recognition (ICPR), Cambridge, UK.

Application:

```{r}
X=iris[,1:4]
nn(X,k=4)
```

#### c) Outlier detection using kth Nearest Neighbour Distance method
Technical Summary:

References:
Hautamaki, V., Karkkainen, I., and Franti, P. 2004. Outlier detection using k-nearest neighbour graph. In Proc. IEEE Int. Conf. on Pattern Recognition (ICPR), Cambridge, UK.

Application:

```{r}
X=iris[,1:4]
nnk(X,k=4)
```


### 5. Density-based Approaches
#### a) Outlier detection using Robust Kernal-based Outlier Factor(RKOF) algorithm
Technical Summary:

Reference:
Ester, M., Kriegel, H.-P., Sander, J., and Xu, X. 1996. A density-based algorithm for discovering clusters in large spatial databases with noise. In Proc. Int. Conf. on Knowledge Discovery and Data Mining (KDD), Portland, OR.

Application:
```{r}
X=iris[,1:4]
dens(X,k=4,C=1)
```
#### b) Outlier detection using genralised dispersion
Technical Summary:

Reference:
Jin, W., Tung, A., and Han, J. 2001. Mining top-n local outliers in large databases. In Proc. ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (SIGKDD), San Francisco, CA.

Application:
```{r}
X=iris[,1:4]
disp(X,cutoff=0.99)
```

### 6. Join assessment of outlier detection methods using techniques described under 2 to 5.

Technical Summary: Given the abudance of method to define outliers a most recent strategy is to develop consensus outlier detection method. For example, rules such as majority vote can be applied when the techniques considered are essentially different. Per instance, see "Outlier detection" package function OutlierDetection which finds outlier observations for the data using different methods and labels an observation as outlier based on the intersection of all the methods considered. Using the function edit in R investigate the criterion being used and which techniques were considered. Also, proposed a modification to the function so to consider any technique to include any given number of techniques for outlier detection. Per instance, ensure that you can include the techniques covered under category 1.

Application:
```{r}
X=iris[,1:4]
OutlierDetection(X)
#Unveil the criterion used in OutlierDection function to define outliers using different methods
#edit(OutlierDetection) # uncomment and execute this line
```

## Problem 2: 
Apply the technique discussed above to the data set that you are using as part of the your problem. Please make sure to report the following:

a) summary of you data sets
Consider using summary function and use graphics to display your data

b) Apply all the outlier detection methods described above to your data set as they fit

c) Report outlier based on consensus rule based on all the techniques that applied to your data sets.










